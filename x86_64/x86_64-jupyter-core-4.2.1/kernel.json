{
    "display_name": "PySpark 2.1.0 & Hadoop 2.7.3",
    "language": "python",
    "argv": ["/usr/bin/python", "-m", "ipykernel", "-f", "{connection_file}"],
    "env": {
        "SPARK_HOME": "/opt/spark",
        "PYSPARK_PYTHON": "/usr/bin/python",
        "PYTHONPATH": "/opt/spark/python/:/opt/spark/python/lib/py4j-0.10.4-src.zip",
        "PYTHONSTARTUP": "/opt/spark/python/pyspark/shell.py",
        "PYSPARK_SUBMIT_ARGS": "--master spark://pc-core:7077 pyspark-shell --executor-memory 1g --driver-memory 1g",
        "CAPTURE_STANDARD_OUT": "true",  
        "CAPTURE_STANDARD_ERR": "true"  
    }
}